# model
base_model: thehosy/TheSyx-nano-Init
model_type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer

# loading
load_in_8bit: false
load_in_4bit: false
strict: false
bf16: true
tf32: true

unfrozen_parameters:
  - model.layers.*
  - model.norm.weight

datasets:
  - path: vietgpt/news_summarization_vi  # duongttr/vi-dataset-for-pretrain
    split: train
    field: content
    type: completion
    trust_remote_code: true
    streaming: true

val_set_size: 0
shuffle_merged_datasets: true

max_steps: 20000

sequence_len: 4096
sample_packing: false
pad_to_sequence_len: true

output_dir: /pretraining/output

save_safetensors: true

gradient_accumulation_steps: 2
micro_batch_size: 4
num_epochs: 1
optimizer: adamw_torch
lr_scheduler: cosine
learning_rate: 1e-4

train_on_inputs: false
group_by_length: false

gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
early_stopping_patience:

local_rank:
logging_steps: 50
xformers_attention:
flash_attention: true

use_tensorboard: true

resume_from_checkpoint: 
auto_resume_from_checkpoints: true

warmup_ratio: 0.05
evals_per_epoch: 0
saves_per_epoch: 50
save_total_limit: 3
weight_decay: 0.0

hub_model_id: thehosy/Thesyx-Nano-Base

accelerator_config:
  compute_environment: LOCAL_MACHINE
  debug: false
  machine_rank: 0
  main_training_function: main
  mixed_precision: 'bf16'
  num_machines: 1
  num_processes: 4
  rdzv_backend: static
  same_network: true
  tpu_env: []
  tpu_use_cluster: false
  tpu_use_sudo: false
  use_cpu: false

# fsdp:
#   - full_shard
#   - auto_wrap
# fsdp_config:
#   fsdp_sharding_strategy: 1
#   fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
#   fsdp_transformer_layer_cls_to_wrap: Qwen3MoeDecoderLayer
#   fsdp_state_dict_type: FULL_STATE_DICT
#   fsdp_backward_prefetch: BACKWARD_PRE
#   fsdp_sync_module_states: true
#   fsdp_cpu_ram_efficient_loading: true
#   fsdp_use_orig_params: true
#   fsdp_offload_params: false

fsdp_version: 2
fsdp_config:
  offload_params: false
  cpu_ram_efficient_loading: true
  auto_wrap_policy: TRANSFORMER_BASED_WRAP
  transformer_layer_cls_to_wrap: Qwen3MoeDecoderLayer
  state_dict_type: FULL_STATE_DICT
  reshard_after_forward: true

# special_tokens:
#   pad_token: "<|im_end|>"